---
title: Semantic Search
description: Retrieve relevant images and objects based on natural language and contextual understanding—beyond keyword matching.
---

<Card title="Why It Matters" icon="search">
  Semantic Search helps you discover relevant visual data based on concepts and context—not just labels or keywords. It's ideal for exploration, discovery, and working with unstructured datasets.
</Card>

---

## What Is Semantic Search?

Semantic Search allows you to retrieve images and objects based on the **meaning and context** of your text queries, rather than relying on exact keyword matches. This enables more **intuitive**, **concept-driven** searches that surface results traditional search might miss.

It leverages metadata generated by models like `VL-Image Semantic Search` or `VL-Object Semantic Search` to understand and **match natural language** queries with visual data in your dataset.

---

## How It Works

- Matches queries against **enrichment-generated metadata**—not just existing tags or labels.
- Works with both **image-level and object-level** results, depending on your current view and which model has been run.
- Requires running `VL-Image Semantic Search` or `VL-Object Semantic Search` on the dataset.
- Best suited for discovering patterns, exploring abstract concepts, or navigating datasets without needing exact class names.

---

## Example Queries

Try using natural phrases like:

- **Simple:** `"sunset over mountains"`  
- **Detailed:** `"bright sunset over rocky mountains with clear sky"`  
- **Combined Attributes:** `"blue sports car on city street at night"`

<Tip>
The more specific your query, the more focused your results. But even broad terms like `"crowd"`, `"outdoor event"`, or `"forest animals"` work well with semantic search.
</Tip>
