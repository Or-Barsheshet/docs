---
title: "ðŸ”µExplore Model Catalog"
slug: "enrichment-models"
excerpt: ""
hidden: true
createdAt: "Tue Mar 11 2025 16:57:51 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Mon Mar 24 2025 15:53:29 GMT+0000 (Coordinated Universal Time)"
---
With Visual Layerâ€™s data enrichment hub, you can enhance your data by generating metadata using advanced, cutting-edge models. This will enable you to:

- Gain deeper insights and unlock more value from your data.
- Easily search, filter, and segment your visual data based on the newly generated metadata.
- Effortlessly curate and organize your data.

# Model Catalog

Enhance your dataset with a diverse set of enrichment models, tailored to extract deeper insights:

|           Model Name          |          Task Type         |                                               Description                                              |
| :---------------------------: | :------------------------: | :----------------------------------------------------------------------------------------------------: |
|     **VL-Object-Detector**    |      Object Detection      | Identifies and locates objects within images or videos by drawing bounding boxes and classifying them. |
|      **VL-Image-Tagger**      | Multi-Class Classification |    Assigns labels or tags to an entire image, categorizing content for identification and analysis.    |
|    **VL-Object-Captioner**    |       Object to Text       |                        Generates descriptive text summarizing detected objects.                        |
|     **VL-Image-Captioner**    |        Image to Text       |           Generates descriptive text summarizing the content and context of an entire image.           |
|  **VL-Image-Semantic Search** |    Semantic Image Search   |      Allows image search with conceptual queries, identifying content that matches search intent.      |
| **VL-Object-Semantic Search** |   Semantic Object Search   |            Finds objects in images/videos based on meaning and context, beyond simple tags.            |
|       **NVILA-Lite-2B**       |  Image-Text-to-Text (VQA)  |           Optimized for efficiency and accuracy in video understanding and multi-image tasks.          |
|        **Janus-Pro-1B**       |  Image-Text-to-Text (VQA)  |               Autoregressive framework for multimodal understanding and text generation.               |

**Object/Image Captioner **and **Object/Image Semantic Search** require labels before enrichmentâ€”whether they come from user annotations, the Object Detector model, or the Image Tagger model.
