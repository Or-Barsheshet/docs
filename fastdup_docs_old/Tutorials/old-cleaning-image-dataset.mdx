---
title: "Old Cleaning Image Dataset"
excerpt: ""
hidden: true
metadata: 
  image: []
  robots: "index"
createdAt: "Tue Mar 21 2023 05:51:14 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Thu Oct 26 2023 05:37:19 GMT+0000 (Coordinated Universal Time)"
---
# Find duplicate images in the dataset

We can see from the prompt that most of the data isn't in similarity clusters, indicating that the threshold is too high. 

Let's start by quickly visualizing the similarity clusters found by fastdup, and then re-run with a lower threshold.

## Visualize

```python
fd.vis.component_gallery()
```

![](https://files.readme.io/ebdfdc1-Screen_Shot_2023-02-27_at_9.28.17.png)

![](https://i.imgur.com/k5ps2hH.png)

## Get a list of image similarity clusters

This is the image-level cluster table. It simply assigns each image to its cluster, and gives some general cluster statistics. 

```python
cc_df, _ = fd.connected_components()
cc_df[cc_df['count'] > 0.0].sort_values(by=['count'], ascending=False).head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fastdup_id</th>
      <th>component_id</th>
      <th>sum</th>
      <th>count</th>
      <th>mean_distance</th>
      <th>min_distance</th>
      <th>max_distance</th>
      <th>img_filename</th>
      <th>error_code</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>33578</th>
      <td>33579</td>
      <td>33470</td>
      <td>5.8491</td>
      <td>6.0</td>
      <td>0.9749</td>
      <td>0.9667</td>
      <td>0.9896</td>
      <td>edamame/3112981.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>19381</th>
      <td>19382</td>
      <td>19342</td>
      <td>5.8772</td>
      <td>6.0</td>
      <td>0.9795</td>
      <td>0.9756</td>
      <td>0.9824</td>
      <td>chicken_quesadilla/2388429.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>83939</th>
      <td>83940</td>
      <td>83759</td>
      <td>5.8665</td>
      <td>6.0</td>
      <td>0.9778</td>
      <td>0.9675</td>
      <td>0.9917</td>
      <td>red_velvet_cake/754664.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>35891</th>
      <td>35892</td>
      <td>35808</td>
      <td>5.8790</td>
      <td>6.0</td>
      <td>0.9798</td>
      <td>0.9780</td>
      <td>0.9819</td>
      <td>escargots/637188.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>35890</th>
      <td>35891</td>
      <td>35808</td>
      <td>5.8790</td>
      <td>6.0</td>
      <td>0.9798</td>
      <td>0.9780</td>
      <td>0.9819</td>
      <td>escargots/637187.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

We can also group by clusters. A few similarity clusters are found with very high similarity, but we are probably just scratching the surface.

### Analyzing image similarity clusters:

We can also group by cluster:

```python
def get_clusters(df, sort_by='count', min_count=2, ascending=False):
    agg_dict = {'img_filename': list, 'mean_distance': max, 'count': len}
    df = df[df['count'] >= min_count]
    grouped_df = df.groupby('component_id').agg(agg_dict).sort_values(by=[sort_by], ascending=ascending)
    return grouped_df

cluster_df = get_clusters(cc_df)
```

By default, we sort by the size of the cluster:

```python
cluster_df.head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_filename</th>
      <th>mean_distance</th>
      <th>count</th>
    </tr>
    <tr>
      <th>component_id</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26475</th>
      <td>[crab_cakes/2780617.jpg, crab_cakes/2780621.jpg, crab_cakes/2780623.jpg]</td>
      <td>0.9759</td>
      <td>3</td>
    </tr>
    <tr>
      <th>74267</th>
      <td>[peking_duck/2551922.jpg, peking_duck/2551971.jpg, peking_duck/3375577.jpg]</td>
      <td>0.9678</td>
      <td>3</td>
    </tr>
    <tr>
      <th>23608</th>
      <td>[churros/3303267.jpg, churros/3303373.jpg, churros/3303522.jpg]</td>
      <td>0.9681</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

We can also sort by distance, having the closest images at the top:

```python
get_clusters(cc_df, sort_by='mean_distance').head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_filename</th>
      <th>mean_distance</th>
      <th>count</th>
    </tr>
    <tr>
      <th>component_id</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>131</th>
      <td>[apple_pie/1461580.jpg, apple_pie/1469191.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>9852</th>
      <td>[breakfast_burrito/662420.jpg, breakfast_burrito/662424.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19115</th>
      <td>[chicken_quesadilla/1579819.jpg, chicken_quesadilla/1590716.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

It's a good start, but as we can see there are not that many duplicates here, and the data may contain more. Let's lower the threshold a bit and re-evaluate the duplicates case.

> ðŸ“˜ Cluster threshold in fastdup
> 
> The threshold that controls the minimal distance for clustering is the `cc_threshold` parameter, setting the threshold for the connected components clustering. Default is `0.96`. 
> 
> The best threshold depends on both data and use case:
> 
> - A _higher_ threshold would cluster images that are highly similar and even duplicates, but would cluster less images.
> - A _lower_ threshold would cluster more similar images together, but clusters would have more diversity and a larger possible difference between images.

## Set a lower similarity threshold, and re-run

Setting a threshold is product of trial and error, until we find a threshold that provides us with large cluster that are highly similar. It depends mostly on your data and use case.

Now we have more clusters containing more of the images, and we are able to remove highly similar images with higher recall.

```python
fd.run(cc_threshold=0.9, overwrite=True)
```

```
FastDup Software, (C) copyright 2022 Dr. Amir Alush and Dr. Danny Bickson.

2023-02-23 16:02:39 [WARNING] Warning: test_dir and input_dir should not point to the same directory 
2023-02-23 16:02:39 [INFO] Going to loop over dir /Users/amirm/vl_data/food-101/images
2023-02-23 16:02:41 [INFO] Found total 101001 images to run on
[â–                                                  ] 2% Estimated: 2 Minutes 0 Featuresple_pie/broken_image.jpg - zero size encountered[â–                                                  ] 2% Estimated: 2 Minutes 0 Features

Failed to read file /Users/amirm/vl_data/food-101/images/apple_pie/broken_image.jpg - zero size encountered

2023-02-23 16:05:04 [INFO] Found total 101001 images to run onmated: 0 Minutes 0 Features
2023-02-23 16:06:04 [INFO] 59838) Finished write_index() NN model
2023-02-23 16:06:04 [INFO] Stored nn model index file /Users/amirm/vl_workdir/food_101/images/nnf.index
2023-02-23 16:06:19 [INFO] Total time took 217959 ms
2023-02-23 16:06:19 [INFO] Found a total of 170 fully identical images (d>0.990), which are 0.06 %
2023-02-23 16:06:19 [INFO] Found a total of 88 nearly identical images(d>0.980), which are 0.03 %
2023-02-23 16:06:19 [INFO] Found a total of 5237 above threshold images (d>0.900), which are 1.73 %
2023-02-23 16:06:19 [INFO] Found a total of 10100 outlier images         (d<0.050), which are 3.33 %
2023-02-23 16:06:19 [INFO] Min distance found 0.379 max distance 1.000
2023-02-23 16:06:19 [INFO] Running connected components for ccthreshold 0.900000 

 ########################################################################################

Dataset Analysis Summary: 

    Dataset contains 101000 images
    Valid images are 100.00% (101,000) of the data, invalid are 0.00% (0) of the data
    Similarity:  1.69% (1,705) belong to 30 similarity clusters (components).
    98.31% (99,295) images do not belong to any similarity cluster.
    Largest cluster has 79 (0.08%) images.
    For a detailed analysis, use `.connected_components()`.

    Outliers: 5.99% (6,047) of images are possible outliers, and fall in the bottom 5.00% of similarity values.
    For a detailed list of outliers, use `.outliers(data=True)`.
```

Now we see a much larger amount of images clustered together. For training mo

```python
cc09_df, _ = fd.connected_components()
cc09_df[cc09_df['count'] > 0.0].sort_values(by=['count'], ascending=False).head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fastdup_id</th>
      <th>component_id</th>
      <th>sum</th>
      <th>count</th>
      <th>mean_distance</th>
      <th>min_distance</th>
      <th>max_distance</th>
      <th>img_filename</th>
      <th>error_code</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>40165</th>
      <td>40166</td>
      <td>24820</td>
      <td>73.0287</td>
      <td>79.0</td>
      <td>0.9244</td>
      <td>0.9004</td>
      <td>0.9467</td>
      <td>french_fries/1700344.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>40706</th>
      <td>40707</td>
      <td>24820</td>
      <td>73.0287</td>
      <td>79.0</td>
      <td>0.9244</td>
      <td>0.9004</td>
      <td>0.9467</td>
      <td>french_fries/3499831.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>40686</th>
      <td>40687</td>
      <td>24820</td>
      <td>73.0287</td>
      <td>79.0</td>
      <td>0.9244</td>
      <td>0.9004</td>
      <td>0.9467</td>
      <td>french_fries/3405511.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>40027</th>
      <td>40028</td>
      <td>24820</td>
      <td>73.0287</td>
      <td>79.0</td>
      <td>0.9244</td>
      <td>0.9004</td>
      <td>0.9467</td>
      <td>french_fries/1099260.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>40175</th>
      <td>40176</td>
      <td>24820</td>
      <td>73.0287</td>
      <td>79.0</td>
      <td>0.9244</td>
      <td>0.9004</td>
      <td>0.9467</td>
      <td>french_fries/1740113.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

## Looking at the new similarity clusters

The largest clusters are now much larger:

```python
 fd.vis.component_gallery()
```

![](https://files.readme.io/2788561-Screen_Shot_2023-02-27_at_9.31.43.png)

Two largest clusters now contain 40 and 33 images, up from just 3 images when using the default threshold. 

The lower clustering threshold allows clustering together images with larger distances, i.e., more diverse. These are no longer near-exact duplicates, but are still very resemblant in terms of what is in the image, lighting, angle, etc. 

## Get a list of near-duplicate images to remove

Let's assume we are selecting a sub-sample of this dataset to be sent, and we want to avoid labeling identical images, and also reduce the amount of highly similar images. We've adjusted the threshold a few times, and selected the threshold set above (`cc_threshold=0.9`).

### List the largest clusters. These include non-identical but more images

```python
cluster09_df = get_clusters(cc09_df)
cluster09_df.head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_filename</th>
      <th>mean_distance</th>
      <th>count</th>
    </tr>
    <tr>
      <th>component_id</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24820</th>
      <td>[club_sandwich/1297247.jpg, club_sandwich/1318118.jpg, club_sandwich/1886101.jpg, club_sandwich/2778614.jpg, club_sandwich/3106065.jpg, club_sandwich/588478.jpg, french_fries/1099260.jpg, french_fries/1295274.jpg, ...]</td>
      <td>0.9244</td>
      <td>40</td>
    </tr>
    <tr>
      <th>18236</th>
      <td>[chicken_curry/2394967.jpg, chicken_curry/2701143.jpg, chicken_curry/882723.jpg, hot_and_sour_soup/1151861.jpg, hot_and_sour_soup/1167380.jpg, hot_and_sour_soup/1400511.jpg, lobster_bisque/3414592.jpg, ...]</td>
      <td>0.9250</td>
      <td>33</td>
    </tr>
    <tr>
      <th>26404</th>
      <td>[crab_cakes/3467918.jpg, pad_thai/1709738.jpg, pad_thai/3059603.jpg, spaghetti_bolognese/3565695.jpg, spaghetti_carbonara/1117183.jpg, spaghetti_carbonara/1390373.jpg, spaghetti_carbonara/1559267.jpg, ...]</td>
      <td>0.9279</td>
      <td>29</td>
    </tr>
  </tbody>
</table>
</div>

### List the clusters with the highest similarity

```python
get_clusters(cc09_df, sort_by='mean_distance').head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_filename</th>
      <th>mean_distance</th>
      <th>count</th>
    </tr>
    <tr>
      <th>component_id</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>98818</th>
      <td>[waffles/899285.jpg, waffles/961486.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>18987</th>
      <td>[chicken_quesadilla/1579819.jpg, chicken_quesadilla/1590716.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>49227</th>
      <td>[grilled_salmon/1574226.jpg, grilled_salmon/1574235.jpg]</td>
      <td>1.0</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

> ðŸ“˜ Analyzing the clusters:
> 
> Right off the bat we can see some possible mislabels in the filenames - clusters containing samples from several very different classes - club sandwich and french fries in the first cluster, chicken curry and hot and sour soup, among others. 
> 
> fastdup is a powerful tool for finding and mitigating mislabeling issues, and extracting mislabels from the cluster dataframe is a solid way to start finding mislabeling issues.

Now that we got our clusters, let's assume we want to remove duplicates with high recall - meaning we want all duplicates removed even at the cost of removing some not duplicates. If this isn't your case, simply raise the threshold to the point the meet your needs. 

We keep a single example from each cluster, and add all the rest to the list of images to be discarded.

```python
# First sample from each cluster that is kept
images_to_keep = list()
cluster_images_to_discard = list()

for cluster_files in cluster09_df.img_filename:
    images_to_keep.append(cluster_files[0])
    cluster_images_to_discard.extend(cluster_files[1:])
cluster_images_to_discard = set(cluster_images_to_discard)
print(f"Found {len(cluster_images_to_discard)} highly similar images to discard")
```

```
Found 2127 highly similar images to discard
```

# Find image outliers

Datasets often contain images that just slipped in and have nothing to do with the task at hand. Finding and removing those is key to better datasets, and for avoiding unnecessary labeling costs, and label noise.

```python
fd.outliers().sort_values(by='distance').head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>outlier</th>
      <th>nearest</th>
      <th>distance</th>
      <th>img_filename_outlier</th>
      <th>error_code_outlier</th>
      <th>is_valid_outlier</th>
      <th>img_filename_nearest</th>
      <th>error_code_nearest</th>
      <th>is_valid_nearest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>430</th>
      <td>9798</td>
      <td>96132</td>
      <td>0.379365</td>
      <td>breakfast_burrito/462294.jpg</td>
      <td>VALID</td>
      <td>True</td>
      <td>tacos/1505262.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4137</th>
      <td>63326</td>
      <td>38291</td>
      <td>0.429240</td>
      <td>macarons/2117640.jpg</td>
      <td>VALID</td>
      <td>True</td>
      <td>fish_and_chips/2079080.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5679</th>
      <td>96132</td>
      <td>83668</td>
      <td>0.515787</td>
      <td>tacos/1505262.jpg</td>
      <td>VALID</td>
      <td>True</td>
      <td>red_velvet_cake/3143813.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

## Visualize outliers

Looking at the outlier gallery, we can see some highly unrelated and irrelevant images to our end goal of classifying different foods. While some are blank, other are highly unrelated and may affect our model results, like beaches and cranes. They are most definitely images that should not be sent for expensive annotation.

```python
fd.vis.outliers_gallery()
```

![](https://files.readme.io/b7cdc15-Screen_Shot_2023-02-27_at_9.44.16.png)

![](https://i.imgur.com/4h9oWOY.png)

# Remove broken and corrupted images

Using fastdup we are able to recover a list of files that are corrupted or that could not be loaded from various reasons. The reason is listed for each image. We will fetch them, and add them to our list of images to remove. Food-101 is meticoulsly curated, so just for the sake of demonstration we've added one empty image.

```python
inv = fd.invalid_instances()
inv
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead tr th {
    text-align: left;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>img_filename</th>
      <th>fastdup_id</th>
      <th>error_code</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>apple_pie/broken_image.jpg</td>
      <td>101001</td>
      <td>ERROR_ZERO_SIZE_FILE</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>

# Find dark, bright and blurry images

```python
fd.img_stats().head(3)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fastdup_id</th>
      <th>img_w</th>
      <th>img_h</th>
      <th>unique</th>
      <th>blur</th>
      <th>mean</th>
      <th>min</th>
      <th>max</th>
      <th>stdv</th>
      <th>file_size</th>
      <th>contrast</th>
      <th>img_filename</th>
      <th>error_code</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>308</td>
      <td>512</td>
      <td>256</td>
      <td>2538.7280</td>
      <td>113.0935</td>
      <td>0.0</td>
      <td>255.0</td>
      <td>53.7116</td>
      <td>42196</td>
      <td>1.0000</td>
      <td>apple_pie/1005649.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>512</td>
      <td>512</td>
      <td>252</td>
      <td>334.7137</td>
      <td>131.6409</td>
      <td>4.0</td>
      <td>255.0</td>
      <td>55.6296</td>
      <td>40760</td>
      <td>0.9691</td>
      <td>apple_pie/1011328.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>384</td>
      <td>512</td>
      <td>255</td>
      <td>728.2955</td>
      <td>117.8109</td>
      <td>0.0</td>
      <td>255.0</td>
      <td>29.5684</td>
      <td>33835</td>
      <td>1.0000</td>
      <td>apple_pie/101251.jpg</td>
      <td>VALID</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

```python
fd.vis.stats_gallery(metric='blur')
```

![](https://files.readme.io/8522be2-Screen_Shot_2023-02-27_at_12.55.37.png)

```python
fd.vis.stats_gallery(metric='dark')
```

![](https://files.readme.io/4aa7fb2-Screen_Shot_2023-02-27_at_12.55.53.png)

```python
fd.vis.stats_gallery(metric='bright')
```

![](https://files.readme.io/79033d8-Screen_Shot_2023-02-27_at_12.56.05.png)

# Wrap up and collect file list for export

```python
stats_df = fd.img_stats()
outlier_df = fd.outliers()
outliers_filtered = outlier_df[outlier_df.distance < 0.68].img_filename_outlier.tolist()
images_to_remove = {
    'duplicates': cluster_images_to_discard,
    'outliers_to_discard': outliers_filtered,
    'invalid_images': fd.invalid_instances(),
    'blurry_images': stats_df[stats_df['blur'] < 50],
    'dark_images': stats_df[stats_df['mean'] < 13],
    'bright_images': stats_df[stats_df['mean'] > 220.5],
)
```

```python
images_to_discard = list()
for key, data_slice in images_to_remove.items():
    ext = data_slice if isinstance(data_slice, list) else data_slice['img_filename'].tolist() 
    print(f"{key}: {len(data_slice)}")
    images_to_discard.extend(ext)
print(f"Total - {len(set(images_to_discard))} unique images")
```

```
duplicates: 2127
outliers_to_discard: 171
invalid_images: 0
blurry_images: 30
dark_images: 6
bright_images: 13
Total - 2339 unique images
```
