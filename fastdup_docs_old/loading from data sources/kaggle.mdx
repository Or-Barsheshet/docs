---
title: "Kaggle"
excerpt: "Analyze any computer vision datasets from [Kaggle](https://kaggle.com)."
hidden: false
metadata: 
  image: []
  robots: "index"
createdAt: "Wed Aug 23 2023 09:03:57 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Thu Oct 26 2023 05:37:19 GMT+0000 (Coordinated Universal Time)"
---
[![Open in Colab](https://img.shields.io/badge/Open%20in%20Colab-blue?style=for-the-badge&logo=data:image/png;base64,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&labelColor=gray)](https://colab.research.google.com/github/visual-layer/fastdup/blob/main/examples/analyzing-kaggle-datasets.ipynb)Â [![Open in Kaggle](https://img.shields.io/badge/Open%20in%20Kaggle-blue?style=for-the-badge&logo=data:image/png;base64,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&labelColor=gray)](https://kaggle.com/kernels/welcome?src=https://github.com/visual-layer/fastdup/blob/main/examples/analyzing-kaggle-datasets.ipynb)

# Sign Up

To load any dataset from Kaggle you first need to [sign-up](https://www.kaggle.com/) for an account. It's free.

On Kaggle, you can browse for a dataset of interest and manually download it on your machine. 

![](https://files.readme.io/472c2fd-image.png)

# Kaggle API

Alternatively, you can use the Kaggle API to programmatically download any dataset using Python.

To install the Kaggle API run

```shell
pip install -Uq kaggle
```

After signing up for an account Kaggle account, head over to the 'Account' tab and select 'Create API Token'. This will trigger the download of `kaggle.json`, a file containing your API credentials. 

![](https://files.readme.io/d183672-image.png)

Place this file in the location `~/.kaggle/kaggle.json` (on Windows in the location `C:\Users\<Windows-username>\.kaggle\kaggle.json`. Read more [here](https://github.com/Kaggle/kaggle-api#api-credentials).

If the setup is done correctly, you should be able to run the Kaggle commands on your terminal. For instance, to list Kaggle datasets that have the term "computer vision", run

```shell
kaggle datasets list -s "computer vision"
```

```
ref                                                           title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  
------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  
jeffheaton/iris-computer-vision                               Iris Computer Vision                                  5MB  2020-11-24 21:23:29           1415         20  0.875            
bhavikardeshna/visual-question-answering-computer-vision-nlp  Visual Question Answering- Computer Vision & NLP    411MB  2022-06-14 04:32:28            421         37  0.8235294        
sanikamal/horses-or-humans-dataset                            Horses Or Humans Dataset                            307MB  2019-04-24 20:09:38           8405        120  0.875            
phylake1337/fire-dataset                                      FIRE Dataset                                        387MB  2020-02-25 16:45:29          12098        180  0.875            
fedesoriano/cifar100                                          CIFAR-100 Python                                    161MB  2020-12-26 08:37:10           4881        116  1.0              
fedesoriano/chinese-mnist-digit-recognizer                    Chinese MNIST in CSV - Digit Recognizer               8MB  2021-06-08 12:15:47            966         45  1.0              
bulentsiyah/opencv-samples-images                             OpenCV samples (Images)                              13MB  2020-05-19 14:36:01           2374         72  0.75             
jeffheaton/traveling-salesman-computer-vision                 Traveling Salesman Computer Vision                    3GB  2022-04-20 01:13:17            183         22  0.875            
sanikamal/rock-paper-scissors-dataset                         Rock Paper Scissors Dataset                         452MB  2019-04-24 19:53:04           4556         78  0.875            
muratkokludataset/dry-bean-dataset                            Dry Bean Dataset                                      5MB  2022-04-02 23:19:30           2303       1464  0.9375           
juniorbueno/opencv-facial-recognition-lbph                    OpenCV - Facial Recognition - LBPH                    6MB  2021-12-01 10:47:12            487         45  0.875            
rickyjli/chinese-fine-art                                     Chinese Fine Art                                    323MB  2020-05-02 03:00:40            821         38  0.8235294        
mpwolke/cusersmarildownloadsmondrianpng                       Computer Vision. C'est  Audacieux, Luxueux,  Chic!  417KB  2022-04-10 21:41:35             10         20  1.0              
paultimothymooney/cvpr-2019-papers                            CVPR 2019 Papers                                      5GB  2019-06-16 18:28:50            934         50  0.875            
emirhanai/human-action-detection-artificial-intelligence      Human Action Detection - Artificial Intelligence    147MB  2022-04-22 21:07:24           1468         40  1.0              
vencerlanz09/plastic-paper-garbage-bag-synthetic-images       Plastic - Paper - Garbage Bag Synthetic Images      451MB  2022-08-26 09:57:18           1127         76  0.875            
shaunthesheep/microsoft-catsvsdogs-dataset                    Cats-vs-Dogs                                        788MB  2020-03-12 05:34:30          27897        345  0.875            
birdy654/cifake-real-and-ai-generated-synthetic-images        CIFAKE: Real and AI-Generated Synthetic Images      105MB  2023-03-28 16:00:29           1702         44  0.875            
ryanholbrook/computer-vision-resources                        Computer Vision Resources                            13MB  2020-07-23 10:40:17           2491         11  0.1764706        
fedesoriano/qmnist-the-extended-mnist-dataset-120k-images     QMNIST - The Extended MNIST Dataset (120k images)    19MB  2021-07-24 15:31:01            844         29  1.0     
```

See more commands [here](https://github.com/Kaggle/kaggle-api#commands). 

Optionally, you can also browse the Kaggle webpage to see the dataset you're interested to download.

# Download Dataset

Let's say we're interested in analyzing the [RVL-CDIP Test Dataset](https://www.kaggle.com/datasets/pdavpoojan/the-rvlcdip-dataset-test). 

You can head to the dataset page click on the 'Copy API command' button and paste it into your terminal.

![](https://files.readme.io/a51cf4f-image.png)

```shell
kaggle datasets download -d pdavpoojan/the-rvlcdip-dataset-test
```

Once done, we should have a the-rvlcdip-dataset-test.zip in the current directory.

Let's unzip the file for further analysis with fastdup in the next section.

```shell
unzip -q the-rvlcdip-dataset-test.zip
```

Once completed, we should have a folder with the name `test/` which contains all the images from the dataset.

# Install fastdup

Now that we have our dataset in place, let's install fastdup.

```shell
pip install fastdup
```

Now, test the installation by printing the version. If there's no error message, we are ready to go.

```python
import fastdup
fastdup.__version__
```

```
'1.36'
```

# Load Annotations

> ð Info
> 
> This step is optional. fastdup works with both labeled and unlabeled datasets.
> 
> If you decide not to load the annotations you can simply run fastdup with just the following codes.
> 
> ```python
> import fastdup  
> fd = fastdup.create(input_dir="IMAGE_FOLDER/")  
> fd.run()
> ```

Although you can run fasdup without the annotations, specifying the labels lets us do more analysis with fastdup such as inspecting mislabels.

Since the dataset is labeled, let's make use of the labels and feed them into fastdup.

fastdup expects the labels to be formatted into a Pandas DataFrame with the columns `filename` and `label`.

Let's loop over the directory recursively search for the filenames and labels, and format them into a DataFrame. 

```python
import glob
import os
import pandas as pd

# Define the path
path = "test/"

# Define patterns for tif image found in the dataset
patterns = ['*tif']

# Use glob to get all image filenames for both extensions
filenames = [f for pattern in patterns for f in glob.glob(path + '**/' + pattern, recursive=True)]

# Extract the parent folder name for each filename
label = [os.path.basename(os.path.dirname(filename)) for filename in filenames]

# Convert to a pandas DataFrame and add the title label column
df = pd.DataFrame({
    'filename': filenames,
    'label': label
})
```

```python
df.head()
```

[block:html]
{
  "html": "<!DOCTYPE html>\n<html>\n<head>\n\t<title></title>\n</head>\n<body>\n\t<table border=\"1\" class=\"dataframe\">\n\t\t<thead>\n\t\t\t<tr style=\"text-align: left;\">\n\t\t\t\t<th></th>\n\t\t\t\t<th>filename</th>\n\t\t\t\t<th>label</th>\n\t\t\t</tr>\n\t\t</thead>\n\t\t<tbody>\n\t\t\t<tr>\n\t\t\t\t<th>0</th>\n\t\t\t\t<td>test/advertisement/12636110.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<th>1</th>\n\t\t\t\t<td>test/advertisement/926916.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<th>2</th>\n\t\t\t\t<td>test/advertisement/502599726+-9726.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<th>3</th>\n\t\t\t\t<td>test/advertisement/509132392+-2392.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<th>4</th>\n\t\t\t\t<td>test/advertisement/12888045.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t</tr>\n\t\t</tbody>\n\t</table>'\n</body>\n</html>"
}
[/block]


# Run fastdup

To fastdup with the annotations DataFrame, let's point the `input_dir` to the image folders and annotations to `df` DataFrame. 

```python
fd = fastdup.create(input_dir='test')
fd.run(annotations=df)
```

Now sit back and relax as fastdup analyzes the dataset.

# Broken Images

Let's inspect the dataset to find if we have any broken images.

```python
fd.invalid_instances()
```

[block:html]
{
  "html": "<div style=\"overflow-x:auto;\">\n    <table border=\"1\" class=\"dataframe\">\n        <thead>\n            <tr style=\"text-align: right;\">\n                <th></th>\n                <th>filename</th>\n                <th>label</th>\n                <th>index</th>\n                <th>error_code</th>\n                <th>is_valid</th>\n                <th>fd_index</th>\n            </tr>\n        </thead>\n        <tbody>\n            <tr>\n                <th>18039</th>\n                <td>test/scientific_publication/2500126531_2500126536.tif</td>\n                <td>scientific_publication</td>\n                <td>18039</td>\n                <td>ERROR_CORRUPT_IMAGE</td>\n                <td>False</td>\n                <td>18039</td>\n            </tr>\n        </tbody>\n    </table>\n</div>\n"
}
[/block]


# Duplicates

Let's visualize the duplicates in a gallery.

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/0587bf1-_media_dnth_Active-Projects_fastdup_examples_work_dir_galleries_duplicates.html.png",
        "",
        ""
      ],
      "align": "center"
    }
  ]
}
[/block]


To get a detailed DataFrame on the duplicates/near-duplicate found, use the `similarity`method.

```python
similarity_df = fd.similarity()  
similarity_df.head()
```

[block:html]
{
  "html": "<!DOCTYPE html>\n<html>\n<head>\n\t<title></title>\n</head>\n<body>\n\t<div style=\"overflow-x:auto;\">\n\t\t<table border=\"1\" class=\"dataframe\">\n\t\t\t<thead>\n\t\t\t\t<tr style=\"text-align: right;\">\n\t\t\t\t\t<th></th>\n\t\t\t\t\t<th>from</th>\n\t\t\t\t\t<th>to</th>\n\t\t\t\t\t<th>distance</th>\n\t\t\t\t\t<th>filename_from</th>\n\t\t\t\t\t<th>label_from</th>\n\t\t\t\t\t<th>index_x</th>\n\t\t\t\t\t<th>error_code_from</th>\n\t\t\t\t\t<th>is_valid_from</th>\n\t\t\t\t\t<th>fd_index_from</th>\n\t\t\t\t\t<th>filename_to</th>\n\t\t\t\t\t<th>label_to</th>\n\t\t\t\t\t<th>index_y</th>\n\t\t\t\t\t<th>error_code_to</th>\n\t\t\t\t\t<th>is_valid_to</th>\n\t\t\t\t\t<th>fd_index_to</th>\n\t\t\t\t</tr>\n\t\t\t</thead>\n\t\t\t<tbody>\n\t\t\t\t<tr>\n\t\t\t\t\t<th>0</th>\n\t\t\t\t\t<td>5323</td>\n\t\t\t\t\t<td>17276</td>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/resume/0001489550.tif</td>\n\t\t\t\t\t<td>resume</td>\n\t\t\t\t\t<td>5323</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>5323</td>\n\t\t\t\t\t<td>test/memo/0001461863.tif</td>\n\t\t\t\t\t<td>memo</td>\n\t\t\t\t\t<td>17276</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>17276</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<th>1</th>\n\t\t\t\t\t<td>21188</td>\n\t\t\t\t\t<td>2189</td>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/scientific_report/2056457981.tif</td>\n\t\t\t\t\t<td>scientific_report</td>\n\t\t\t\t\t<td>21188</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>21188</td>\n\t\t\t\t\t<td>test/advertisement/91572245_91572246.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>2189</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>2189</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<th>2</th>\n\t\t\t\t\t<td>2358</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/advertisement/2072281170.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>2358</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>2358</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<th>3</th>\n\t\t\t\t\t<td>26877</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/news_article/2083785419.tif</td>\n\t\t\t\t\t<td>news_article</td>\n\t\t\t\t\t<td>26877</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>26877</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<th>4</th>\n\t\t\t\t\t<td>20715</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/scientific_report/2505149213.tif</td>\n\t\t\t\t\t<td>scientific_report</td>\n\t\t\t\t\t<td>20715</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>20715</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t\t<td>VALID</td>\n\t\t\t\t\t<td>True</td>\n\t\t\t\t\t<td>1353</td>\n\t\t\t\t</tr>\n\t\t\t</tbody>\n\t\t</table>\n\t</div>\n</body>\n</html>\n"
}
[/block]


We can get the number of duplicates/near-duplicates by filtering them on the `distance` score. A `distance` of `1.0` is an exact copy, and vice versa.

```python
near_duplicates = similarity_df[similarity_df["distance"] >= 0.99]
near_duplicates = near_duplicates[["distance","filename_from", "filename_to", "label_from", "label_to"]]
len(near_duplicates)
```

```
1392
```

Slice the DataFrame to view related columns.

```python
near_duplicates.head()
```

[block:html]
{
  "html": "<!DOCTYPE html>\n<html>\n<head>\n\t<title></title>\n</head>\n<body>\n\t<div style=\"overflow-x:auto;\">\n\t\t<table border=\"1\" class=\"dataframe\">\n\t\t\t<thead>\n\t\t\t\t<tr style=\"text-align: right;\">\n\t\t\t\t\t<th>distance</th>\n\t\t\t\t\t<th>filename_from</th>\n\t\t\t\t\t<th>filename_to</th>\n\t\t\t\t\t<th>label_from</th>\n\t\t\t\t\t<th>label_to</th>\n\t\t\t\t</tr>\n\t\t\t</thead>\n\t\t\t<tbody>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/resume/0001489550.tif</td>\n\t\t\t\t\t<td>test/memo/0001461863.tif</td>\n\t\t\t\t\t<td>resume</td>\n\t\t\t\t\t<td>memo</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/scientific_report/2056457981.tif</td>\n\t\t\t\t\t<td>test/advertisement/91572245_91572246.tif</td>\n\t\t\t\t\t<td>scientific_report</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/advertisement/2072281170.tif</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/news_article/2083785419.tif</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>news_article</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t</tr>\n\t\t\t\t<tr>\n\t\t\t\t\t<td>1.0</td>\n\t\t\t\t\t<td>test/scientific_report/2505149213.tif</td>\n\t\t\t\t\t<td>test/advertisement/2073352207.tif</td>\n\t\t\t\t\t<td>scientific_report</td>\n\t\t\t\t\t<td>advertisement</td>\n\t\t\t\t</tr>\n\t\t\t</tbody>\n\t\t</table>\n\t</div>\n</body>\n</html>\n"
}
[/block]


> ð Tip
> 
> That's a lot of (**1392**) **duplicates**! Not cool for a test dataset. Using fastdup we just conveniently surfaced these duplicates for further action. 
> 
> Typically, we'd just remove these duplicates from the dataset as they do not add value. But we will leave this step to you as the data curator.

# Image Clusters

fastdup also includes a gallery to view image clusters.

```python
fd.vis.component_gallery()
```

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/c70c2f1-_media_dnth_Active-Projects_fastdup_examples_work_dir_galleries_components.html.png",
        "",
        ""
      ],
      "align": "center"
    }
  ]
}
[/block]


> ð Tip
> 
> The components gallery gives a bird's eye view of how similar images exists in your dataset as clusters.

# Statistical Gallery

View the dataset from a statistical point of view to show bright/dark/blurry images from the dataset.

```python
fd.vis.stats_gallery(metric='bright')
```

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/105609b-_media_dnth_Active-Projects_fastdup_examples_work_dir_galleries_mean.html.png",
        "",
        ""
      ],
      "align": "center"
    }
  ]
}
[/block]


[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/b2a240b-_media_dnth_Active-Projects_fastdup_examples_work_dir_galleries_mean.html_1.png",
        "",
        ""
      ],
      "align": "center"
    }
  ]
}
[/block]


> ð Tip
> 
> Not all bright/dark blurry images are useful. In this dataset, we found documents that are totally black or white. We'll leave it to you to decide whether these images are useful.

View DataFrame with image statistics.

```python
fd.img_stats().head()
```

[block:html]
{
  "html": "<!DOCTYPE html>\n<html>\n<head>\n\t<title></title>\n</head>\n<body>\n\t<div style=\"overflow-x:auto;\">\n\t\t<table border=\"1\" class=\"dataframe\">\n\t\t\t<thead>\n\t\t\t\t<tr style=\"text-align: right;\">\n\t\t\t\t\t<th>index</th>\n\t\t\t\t\t<th>img_w</th>\n\t\t\t\t\t<th>img_h</th>\n\t\t\t\t\t<th>unique</th>\n\t\t\t\t\t<th>blur</th>\n\t\t\t\t\t<th>mean</th>\n\t\t\t\t\t<th>min</th>\n\t\t\t\t\t<th>max</th>\n\t\t\t\t\t<th>stdv</th>\n\t\t\t\t\t<th>file_size</th>\n\t\t\t\t\t<th>contrast</th>\n\t\t\t\t\t<th>filename</th>\n\t\t\t\t\t<th>label</th>\n\t\t\t\t\t<th>error_code</th>\n\t\t\t\t\t<th>is_valid</th>\n\t\t\t\t\t<th>fd_index</th>\n\t\t\t\t</tr>\n\t\t\t</thead>\n\t\t\t<tbody>\n        <tr>\n\t\t\t\t<td>0</td>\n\t\t\t\t<td>762</td>\n\t\t\t\t<td>1000</td>\n\t\t\t\t<td>255</td>\n\t\t\t\t<td>21070.7559</td>\n\t\t\t\t<td>229.3038</td>\n\t\t\t\t<td>0.0</td>\n\t\t\t\t<td>255.0</td>\n\t\t\t\t<td>72.2897</td>\n\t\t\t\t<td>106922</td>\n\t\t\t\t<td>1.0</td>\n\t\t\t\t<td>test/advertisement/12636110.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t\t<td>VALID</td>\n\t\t\t\t<td>True</td>\n\t\t\t\t<td>0</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>1</td>\n\t\t\t\t<td>762</td>\n\t\t\t\t<td>1000</td>\n\t\t\t\t<td>256</td>\n\t\t\t\t<td>12831.0820</td>\n\t\t\t\t<td>229.3935</td>\n\t\t\t\t<td>0.0</td>\n\t\t\t\t<td>255.0</td>\n\t\t\t\t<td>74.0765</td>\n\t\t\t\t<td>62048</td>\n\t\t\t\t<td>1.0</td>\n\t\t\t\t<td>test/advertisement/926916.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t\t<td>VALID</td>\n\t\t\t\t<td>True</td>\n\t\t\t\t<td>1</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>2</td>\n\t\t\t\t<td>754</td>\n\t\t\t\t<td>1000</td>\n\t\t\t\t<td>256</td>\n\t\t\t\t<td>41271.8359</td>\n\t\t\t\t<td>196.6943</td>\n\t\t\t\t<td>0.0</td>\n\t\t\t\t<td>255.0</td>\n\t\t\t\t<td>69.2706</td>\n\t\t\t\t<td>589350</td>\n\t\t\t\t<td>1.0</td>\n\t\t\t\t<td>test/advertisement/502599726+-9726.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t\t<td>VALID</td>\n\t\t\t\t<td>True</td>\n\t\t\t\t<td>2</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>3</td>\n\t\t\t\t<td>754</td>\n\t\t\t\t<td>1000</td>\n\t\t\t\t<td>256</td>\n\t\t\t\t<td>15565.9248</td>\n\t\t\t\t<td>243.6986</td>\n\t\t\t\t<td>0.0</td>\n\t\t\t\t<td>255.0</td>\n\t\t\t\t<td>46.8760</td>\n\t\t\t\t<td>73854</td>\n\t\t\t\t<td>1.0</td>\n\t\t\t\t<td>test/advertisement/509132392+-2392.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t\t<td>VALID</td>\n\t\t\t\t<td>True</td>\n\t\t\t\t<td>3</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>4</td>\n\t\t\t\t<td>762</td>\n\t\t\t\t<td>1000</td>\n\t\t\t\t<td>256</td>\n\t\t\t\t<td>11803.9893</td>\n\t\t\t\t<td>247.4764</td>\n\t\t\t\t<td>0.0</td>\n\t\t\t\t<td>255.0</td>\n\t\t\t\t<td>39.0911</td>\n\t\t\t\t<td>54344</td>\n\t\t\t\t<td>1.0</td>\n\t\t\t\t<td>test/advertisement/12888045.tif</td>\n\t\t\t\t<td>advertisement</td>\n\t\t\t\t<td>VALID</td>\n\t\t\t\t<td>True</td>\n\t\t\t\t<td>4</td>\n\t\t\t</tr>\n      </tbody>\n\t\t</table>\n\t</div>\n</body>\n</html>\n"
}
[/block]


# Mislabels

Since we ran fastdup with labels, we can inspect for potential mislabels. Let's first visualize it via the similarity gallery.

```python
fd.vis.similarity_gallery()
```

[block:image]
{
  "images": [
    {
      "image": [
        "https://files.readme.io/d3081ff-_media_dnth_Active-Projects_fastdup_examples_work_dir_galleries_similarity.html.png",
        "",
        ""
      ],
      "align": "center"
    }
  ]
}
[/block]


> ð Tip
> 
> In the similarity gallery fastdup surfaces the images that are visually similar to one another yet has different labels.

# Wrap Up

That's it! We've just conveniently surfaced many issues with this dataset by running fastdup. By taking care of dataset quality issues, we hope this will help you train better models.

Questions about this tutorial? Reach out to us on our [Slack channel](https://visuallayer.slack.com/)!

# VL Profiler - A faster and easier way to diagnose and visualize dataset issues

The team behind fastdup also recently launched [VL Profiler](https://medium.com/visual-layer/introducing-vl-profiler-1cde3257c76c), a no-code cloud-based platform that lets you leverage fastdup in the browser. 

VL Profiler lets you find:

- Duplicates/near-duplicates.
- Outliers.
- Mislabels.
- Non-useful images.

Here's a highlight of the issues found in the RVL-CDIP test dataset on the VL Profiler.

[block:embed]
{
  "html": "<iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fijf8Ag4-3TE%3Ffeature%3Doembed&display_name=YouTube&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dijf8Ag4-3TE&image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fijf8Ag4-3TE%2Fhqdefault.jpg&key=7788cb384c9f4d5dbbdbeffd9fe4b92f&type=text%2Fhtml&schema=youtube\" width=\"640\" height=\"480\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen; encrypted-media; picture-in-picture;\" allowfullscreen=\"true\"></iframe>",
  "url": "https://www.youtube.com/watch?v=ijf8Ag4-3TE",
  "title": "RVL DCIP Test Dataset - Visual Layer Profiler",
  "favicon": "https://www.google.com/favicon.ico",
  "image": "https://i.ytimg.com/vi/ijf8Ag4-3TE/hqdefault.jpg",
  "provider": "youtube.com",
  "href": "https://www.youtube.com/watch?v=ijf8Ag4-3TE",
  "typeOfEmbed": "youtube"
}
[/block]


> ð Free Usage
> 
> Use VL Profiler for free to analyze issues on your dataset with up to **1,000,000 images**. 
> 
> [Get started for free.](https://app.visual-layer.com?utm_source=fastdupdocs)

Not convinced yet? 

Interact with a collection of dataset like ImageNet-21K, COCO, and DeepFashion [here](https://app.visual-layer.com/vl-datasets?utm_source=fastdupdocs).

No sign-ups needed.

[block:image]
{
  "images": [
    {
      "image": [
        "https://github.com/visual-layer/fastdup/raw/main/gallery/github_banner_profiler.gif",
        null,
        "ima"
      ],
      "align": "center"
    }
  ]
}
[/block]


[block:html]
{
  "html": "<center> \n    <a href=\"https://www.visual-layer.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/visual-layer/visuallayer/main/imgs/vl_horizontal_logo_dark_mode.png\" width=200>\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/visual-layer/visuallayer/main/imgs/vl_horizontal_logo.png\" width=200>\n    <img alt=\"vl logo.\" src=\"https://raw.githubusercontent.com/visual-layer/visuallayer/main/imgs/vl_horizontal_logo.png\" width=200>\n    </picture>\n    </a><br><br>\n    <a href=\"https://github.com/visual-layer/fastdup\" target=\"_blank\" style=\"text-decoration: none;\"> GitHub </a> â¢\n    <a href=\"https://visual-layer.slack.com/\" target=\"_blank\" style=\"text-decoration: none;\"> Join Slack Community </a> â¢\n    <a href=\"https://visual-layer.readme.io/discuss\" target=\"_blank\" style=\"text-decoration: none;\"> Discussion Forum </a>\n</center>\n\n<center> \n    <a href=\"https://medium.com/visual-layer\" target=\"_blank\" style=\"text-decoration: none;\"> Blog </a> â¢\n    <a href=\"https://visual-layer.readme.io/\" target=\"_blank\" style=\"text-decoration: none;\"> Documentation </a> â¢\n    <a href=\"https://visual-layer.com/about\" target=\"_blank\" style=\"text-decoration: none;\"> About Us </a> \n</center>\n\n<center> \n    <a href=\"https://www.linkedin.com/company/visual-layer/\" target=\"_blank\" style=\"text-decoration: none;\"> LinkedIn </a> â¢\n    <a href=\"https://twitter.com/visual_layer\" target=\"_blank\" style=\"text-decoration: none;\"> Twitter </a>\n</center>"
}
[/block]
